# MLflow Integration - All Changes Explained (Simple Terms)

## ğŸ¯ What We Did

We added **MLflow** to your existing project. Think of it as adding a "lab notebook" that automatically records every experiment.

---

## ğŸ“ Files Changed (Summary)

### **NEW Files (Created):**
1. `src/mlflow_tracker.py` - MLflow helper class
2. `pipeline/stage_03_train_model_mlflow.py` - Training with MLflow
3. `serve_model_api.py` - Model serving script
4. `MLFLOW_GUIDE.md` - Documentation

### **MODIFIED Files:**
1. `config/config.yaml` - Enabled MLflow
2. `dvc.yaml` - Updated to use MLflow training
3. `requirements.txt` - Added MLflow package

---

## ğŸ”§ FILE-BY-FILE BREAKDOWN

### **1. src/mlflow_tracker.py** (NEW)

**What it is:** A helper class to make MLflow easier to use

**Simple Analogy:**
> Like a TV remote control. Instead of manually pressing buttons on the TV, you use the remote (easier!).

**The Class:**

```python
class MLflowTracker:
    """Helper for using MLflow"""

    def __init__(self, config):
        # Setup: Where to save MLflow data
        tracking_uri = "file:./logs/mlruns"
        mlflow.set_tracking_uri(tracking_uri)
        mlflow.set_experiment("housing_price_prediction")
```

**What it does:**
```
Tells MLflow:
- Where to save data: logs/mlruns/
- Experiment name: housing_price_prediction
```

**Methods (Functions):**

```python
1. start_run(run_name)
   # What: Start recording an experiment
   # Like: Opening a new page in your lab notebook
   # Example: tracker.start_run("experiment_1")

2. log_params(params)
   # What: Record the settings you used
   # Like: Writing "Used 150 trees, max depth 20"
   # Example: tracker.log_params({'n_estimators': 150})

3. log_metrics(metrics)
   # What: Record the results you got
   # Like: Writing "Got 82% accuracy, $48k error"
   # Example: tracker.log_metrics({'r2_score': 0.82})

4. log_model(model, name)
   # What: Save the trained model
   # Like: Saving your finished cake recipe
   # Example: tracker.log_model(trained_model, "housing_predictor")

5. end_run()
   # What: Finish recording
   # Like: Closing the notebook page
   # Example: tracker.end_run()
```

**Complete Example:**
```python
# Create tracker
tracker = MLflowTracker(config)

# Start experiment
tracker.start_run("my_experiment")

# Record what you did
tracker.log_params({'n_estimators': 150, 'max_depth': 20})

# Record what you got
tracker.log_metrics({'rmse': 48677, 'r2_score': 0.82})

# Save the model
tracker.log_model(my_trained_model, "housing_price_predictor")

# Done!
tracker.end_run()
```

**Why we created this:**
- Makes MLflow easier to use
- Less code to write
- Consistent across project

---

### **2. pipeline/stage_03_train_model_mlflow.py** (NEW)

**What it is:** Modified training script that uses MLflow

**Simple Analogy:**
> Old version: Train model, save to disk
> New version: Train model, save to disk AND record in MLflow

**Main Function:**

```python
def run_model_training_with_mlflow():
    # 1. Setup
    logger = PipelineLogger("stage_03_train_mlflow")
    config = load_config()
    mlflow_tracker = MLflowTracker(config)  # â† NEW!

    # 2. Start MLflow tracking
    run_name = "random_forest_150_trees"
    mlflow_tracker.start_run(run_name)  # â† NEW! Start recording

    # 3. Load data (same as before)
    df = pd.read_csv('data/features/housing_features.csv')

    # 4. Split data (same as before)
    trainer = ModelTrainer(config)
    X_train, X_val, y_train, y_val = trainer.split_data(df)

    # 5. Log to MLflow â† NEW!
    mlflow_tracker.log_params({
        'n_estimators': 150,
        'max_depth': 20,
        'train_samples': 16512
    })

    # 6. Train model (same as before)
    trainer.train(X_train, y_train)

    # 7. Evaluate (same as before)
    evaluator = ModelEvaluator(config)
    y_pred = trainer.predict(X_val)
    report = evaluator.evaluate(y_val, y_pred)

    # 8. Log metrics to MLflow â† NEW!
    mlflow_tracker.log_metrics({
        'rmse': report['metrics']['rmse'],
        'r2_score': report['metrics']['r2_score'],
        'mae': report['metrics']['mae']
    })

    # 9. Log model to MLflow â† NEW!
    mlflow_tracker.log_model(
        trainer.model,
        registered_model_name="housing_price_predictor"
    )

    # 10. End MLflow tracking â† NEW!
    mlflow_tracker.end_run()

    # 11. Save locally (same as before, for backward compatibility)
    trainer.save_model()
    registry.register_model(...)
```

**What Changed:**

**BEFORE (without MLflow):**
```python
# Load data
# Train model
# Evaluate
# Save to disk
# Done!
```

**AFTER (with MLflow):**
```python
# Start MLflow tracking â† NEW
# Load data
# Log parameters to MLflow â† NEW
# Train model
# Evaluate
# Log metrics to MLflow â† NEW
# Log model to MLflow â† NEW
# End MLflow tracking â† NEW
# Save to disk (still do this too!)
# Done!
```

**Why we did this:**
- Records every experiment automatically
- Can compare experiments in UI
- Models versioned in MLflow Registry

---

### **3. config/config.yaml** (MODIFIED)

**What changed:**

```yaml
# BEFORE:
training:
  enable_mlflow: false  # MLflow not installed

model:
  hyperparameters:
    random_forest:
      n_estimators: 100  # Original setting

# AFTER:
training:
  enable_mlflow: true  # â† CHANGED! MLflow now active

model:
  hyperparameters:
    random_forest:
      n_estimators: 300  # â† CHANGED! Experimenting with more trees
```

**Simple Explanation:**
```
enable_mlflow: false  â†’ MLflow tracking OFF
enable_mlflow: true   â†’ MLflow tracking ON (records everything!)

n_estimators: 100  â†’ Use 100 decision trees
n_estimators: 300  â†’ Use 300 decision trees (more = usually better)
```

**Why we changed this:**
- Turn on MLflow tracking
- Experiment with different parameters

---

### **4. dvc.yaml** (MODIFIED)

**What changed:**

```yaml
# BEFORE:
train_model:
  cmd: python pipeline/stage_03_train_model.py  # Old version
  deps:
    - pipeline/stage_03_train_model.py

# AFTER:
train_model:
  cmd: python pipeline/stage_03_train_model_mlflow.py  # â† NEW version with MLflow!
  deps:
    - pipeline/stage_03_train_model_mlflow.py  # â† NEW
    - src/mlflow_tracker.py  # â† NEW dependency
```

**Simple Explanation:**
```
DVC now runs the MLflow-enabled version of training
```

**Why:**
- So `dvc repro` automatically uses MLflow
- Tracks MLflow files as dependencies (reruns if they change)

---

### **5. requirements.txt** (MODIFIED)

**What changed:**

```
# BEFORE:
# mlflow>=2.8.0  # (commented out)

# AFTER:
mlflow>=2.8.0  # Installed! âœ“
```

**Simple Explanation:**
- Added MLflow to list of required packages
- Anyone cloning your project will install MLflow automatically

---

### **6. serve_model_api.py** (NEW)

**What it is:** Script to serve your model as a REST API

**Simple Analogy:**
> Your model becomes a website. You send house data, you get price back.

**Main Function:**

```python
def serve_model_mlflow_cli(model_name="housing_price_predictor", port=5001):
    # 1. Get model from MLflow registry
    client = mlflow.MlflowClient()
    versions = client.search_model_versions(f"name='{model_name}'")

    # 2. Get latest version
    latest_version = versions[0]

    # 3. Create model URI
    model_uri = f"models:/{model_name}/latest"

    # 4. Serve it!
    subprocess.run([
        "mlflow", "models", "serve",
        "-m", model_uri,
        "-p", str(port)
    ])
```

**How it works:**
```
1. Looks in MLflow registry for "housing_price_predictor"
2. Gets the latest version (e.g., v3)
3. Starts a web server on port 5001
4. Server accepts house data via HTTP
5. Returns price predictions
```

**Usage:**
```bash
# Terminal 1: Start server
python serve_model_api.py

# Terminal 2: Send prediction request
curl -X POST http://localhost:5001/invocations -d '{...}'
# Response: {"predictions": [452600.0]}
```

---

## ğŸ”„ How Everything Works Together

Let me show you the **complete flow** with all classes:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  YOU: Run Pipeline                                          â”‚
â”‚  $ dvc repro                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DVC reads: dvc.yaml                                        â”‚
â”‚  Finds: cmd: python pipeline/stage_03_train_model_mlflow.pyâ”‚
â”‚  Runs: That script                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FILE: pipeline/stage_03_train_model_mlflow.py             â”‚
â”‚                                                             â”‚
â”‚  def run_model_training_with_mlflow():                     â”‚
â”‚      # Creates instances of classes:                        â”‚
â”‚      config = load_config()  â† Uses: utils.py              â”‚
â”‚      logger = PipelineLogger()  â† Uses: pipeline_logger.py â”‚
â”‚      mlflow_tracker = MLflowTracker()  â† Uses: mlflow_tracker.py â”‚
â”‚      trainer = ModelTrainer()  â† Uses: models/train.py     â”‚
â”‚      evaluator = ModelEvaluator()  â† Uses: evaluation/evaluate.py â”‚
â”‚      registry = ModelRegistry()  â† Uses: models/registry.pyâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 1: MLflowTracker.start_run()                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  What: Tells MLflow "Start recording experiment"           â”‚
â”‚  Creates: New run in logs/mlruns/                          â”‚
â”‚  Result: Run ID = abc123                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 2: ModelTrainer.split_data()                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  What: Splits 20,640 houses into 80/20                     â”‚
â”‚  Class: ModelTrainer (from src/models/train.py)            â”‚
â”‚  Result: 16,512 training, 4,128 validation                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 3: MLflowTracker.log_params()  â† NEW WITH MLFLOW     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  What: Records settings to MLflow                          â”‚
â”‚  Logs: n_estimators=300, max_depth=20, etc.               â”‚
â”‚  Saved to: logs/mlruns/.../params/                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 4: ModelTrainer.train()                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  What: Trains Random Forest model                          â”‚
â”‚  Class: ModelTrainer (from src/models/train.py)            â”‚
â”‚  Result: Trained model object                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 5: ModelEvaluator.evaluate()                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  What: Tests model on validation set                       â”‚
â”‚  Class: ModelEvaluator (from src/evaluation/evaluate.py)   â”‚
â”‚  Result: {'rmse': 48677, 'r2_score': 0.82, ...}           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 6: MLflowTracker.log_metrics()  â† NEW WITH MLFLOW    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  What: Records results to MLflow                           â”‚
â”‚  Logs: rmse=48677, r2_score=0.82, etc.                    â”‚
â”‚  Saved to: logs/mlruns/.../metrics/                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 7: MLflowTracker.log_model()  â† NEW WITH MLFLOW      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  What: Saves model to MLflow registry                      â”‚
â”‚  Registers as: "housing_price_predictor" v1                â”‚
â”‚  Saved to: logs/mlruns/.../artifacts/model/               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 8: ModelRegistry.register_model()                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  What: Also saves to local registry (backward compatible)  â”‚
â”‚  Class: ModelRegistry (from src/models/registry.py)        â”‚
â”‚  Saved to: models/model_registry/registry.json             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 9: MLflowTracker.end_run()  â† NEW WITH MLFLOW        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  What: Closes the experiment recording                     â”‚
â”‚  Result: All data saved to MLflow!                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Classes Involved (Detailed Explanation)

### **Class 1: MLflowTracker** (NEW)

**Location:** `src/mlflow_tracker.py`

**Purpose:** Wrapper to make MLflow easy to use

**Attributes (Data it holds):**
```python
self.config           # Configuration from config.yaml
self.training_config  # Training settings
self.logger           # For logging messages
```

**Methods (What it can do):**

| Method | What it does | Example |
|--------|-------------|---------|
| `__init__()` | Setup MLflow | `tracker = MLflowTracker(config)` |
| `start_run()` | Start experiment | `tracker.start_run("exp_1")` |
| `log_params()` | Record settings | `tracker.log_params({'n_estimators': 100})` |
| `log_metrics()` | Record results | `tracker.log_metrics({'rmse': 48726})` |
| `log_model()` | Save model | `tracker.log_model(model, "my_model")` |
| `set_tags()` | Add labels | `tracker.set_tags({'stage': 'dev'})` |
| `end_run()` | Finish recording | `tracker.end_run()` |

**Simple Example:**
```python
# Like writing in a lab notebook:

tracker = MLflowTracker(config)  # Open notebook

tracker.start_run("experiment_1")  # New page: "Experiment 1"

# Write settings:
tracker.log_params({'trees': 150})  # "Used 150 trees"

# Write results:
tracker.log_metrics({'accuracy': 0.82})  # "Got 82% accuracy"

tracker.end_run()  # Close page
```

---

### **Class 2: ModelTrainer** (EXISTING, used by MLflow script)

**Location:** `src/models/train.py`

**Purpose:** Handles model training

**What it does:**
```python
trainer = ModelTrainer(config)

# 1. Split data
X_train, X_val, y_train, y_val = trainer.split_data(df)

# 2. Train model
trainer.train(X_train, y_train)

# 3. Make predictions
predictions = trainer.predict(X_val)

# 4. Get feature importance
importance = trainer.get_feature_importance(X_train)

# 5. Save model
model_path = trainer.save_model()
```

**Nothing changed in this class - we just USE it in the MLflow script!**

---

### **Class 3: ModelEvaluator** (EXISTING, used by MLflow script)

**Location:** `src/evaluation/evaluate.py`

**Purpose:** Calculates model performance metrics

**What it does:**
```python
evaluator = ModelEvaluator(config)

# Evaluate model
report = evaluator.evaluate(
    y_true=y_val,      # Actual prices
    y_pred=predictions # Model's predictions
)

# Returns:
{
    'metrics': {
        'rmse': 48677,
        'mae': 31197,
        'r2_score': 0.8192,
        'mape': 17.30
    },
    'threshold_checks': {'rmse_threshold': True, ...},
    'all_checks_passed': True
}
```

**Nothing changed in this class - we just USE its output in MLflow!**

---

### **Class 4: ModelRegistry** (EXISTING, still used)

**Location:** `src/models/registry.py`

**Purpose:** Local model versioning (your original registry)

**What it does:**
```python
registry = ModelRegistry(config)

# Register model locally
version_id = registry.register_model(
    model_path="models/saved_models/model_*.joblib",
    model_metadata={...},
    evaluation_report={...}
)

# Returns: "v_20251030_091537"
```

**Why we keep this:**
- Backward compatibility
- Dual tracking (local + MLflow)
- Local backup if MLflow unavailable

---

### **Class 5: PipelineLogger** (EXISTING, used everywhere)

**Location:** `src/pipeline_logger.py`

**Purpose:** Logs pipeline activities to files

**What it does:**
```python
logger = PipelineLogger("my_stage")

logger.stage_start("Training")  # "========== STAGE: Training - STARTED =========="
logger.info("Processing data...")  # "INFO - Processing data..."
logger.metric("RMSE", 48677)  # "METRIC | RMSE: 48677"
logger.stage_end("Training")  # "========== STAGE: Training - COMPLETED =========="
```

**Still used everywhere - nothing changed!**

---

## ğŸ“Š Complete Data Flow (With Classes)

```
YOU RUN: dvc repro
    â†“
DVC executes: stage_03_train_model_mlflow.py
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Inside stage_03_train_model_mlflow.py:          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                 â”‚
â”‚ config = load_config()                          â”‚
â”‚   â†“                                             â”‚
â”‚   Returns: Dictionary with all settings         â”‚
â”‚                                                 â”‚
â”‚ logger = PipelineLogger(config)                 â”‚
â”‚   â†“                                             â”‚
â”‚   Creates: Logger instance                      â”‚
â”‚   Saves logs to: logs/stage_03_train_*.log     â”‚
â”‚                                                 â”‚
â”‚ mlflow_tracker = MLflowTracker(config)  â† NEW   â”‚
â”‚   â†“                                             â”‚
â”‚   Creates: MLflow tracker instance              â”‚
â”‚   Sets up: logs/mlruns/ directory               â”‚
â”‚                                                 â”‚
â”‚ mlflow_tracker.start_run("random_forest_300")   â”‚
â”‚   â†“                                             â”‚
â”‚   MLflow creates: New experiment folder         â”‚
â”‚   Assigns: Run ID (e.g., abc123)                â”‚
â”‚                                                 â”‚
â”‚ trainer = ModelTrainer(config)                  â”‚
â”‚   â†“                                             â”‚
â”‚   Creates: Trainer instance                     â”‚
â”‚                                                 â”‚
â”‚ X_train, X_val, y_train, y_val =                â”‚
â”‚     trainer.split_data(df)                      â”‚
â”‚   â†“                                             â”‚
â”‚   Splits: 80/20                                 â”‚
â”‚                                                 â”‚
â”‚ mlflow_tracker.log_params({...})  â† NEW         â”‚
â”‚   â†“                                             â”‚
â”‚   MLflow saves: n_estimators=300, etc.          â”‚
â”‚   Location: logs/mlruns/.../params/             â”‚
â”‚                                                 â”‚
â”‚ trainer.train(X_train, y_train)                 â”‚
â”‚   â†“                                             â”‚
â”‚   Trains: Random Forest model                   â”‚
â”‚   Result: trainer.model (trained object)        â”‚
â”‚                                                 â”‚
â”‚ evaluator = ModelEvaluator(config)              â”‚
â”‚   â†“                                             â”‚
â”‚   Creates: Evaluator instance                   â”‚
â”‚                                                 â”‚
â”‚ predictions = trainer.predict(X_val)            â”‚
â”‚   â†“                                             â”‚
â”‚   Predicts: 4,128 house prices                  â”‚
â”‚                                                 â”‚
â”‚ report = evaluator.evaluate(y_val, predictions) â”‚
â”‚   â†“                                             â”‚
â”‚   Calculates: RMSE, RÂ², MAE, MAPE              â”‚
â”‚   Returns: Dictionary with all metrics          â”‚
â”‚                                                 â”‚
â”‚ mlflow_tracker.log_metrics(report['metrics'])   â”‚
â”‚   â†“                                             â”‚
â”‚   MLflow saves: RMSE=48677, RÂ²=0.82, etc.      â”‚
â”‚   Location: logs/mlruns/.../metrics/            â”‚
â”‚                                                 â”‚
â”‚ mlflow_tracker.log_model(trainer.model, ...)    â”‚
â”‚   â†“                                             â”‚
â”‚   MLflow saves: Complete trained model          â”‚
â”‚   Registers: "housing_price_predictor" v2       â”‚
â”‚   Location: logs/mlruns/.../artifacts/model/    â”‚
â”‚                                                 â”‚
â”‚ registry = ModelRegistry(config)                â”‚
â”‚ registry.register_model(...)                    â”‚
â”‚   â†“                                             â”‚
â”‚   Local registry saves: v_20251030_091537       â”‚
â”‚   Location: models/model_registry/registry.json â”‚
â”‚                                                 â”‚
â”‚ mlflow_tracker.end_run()  â† NEW                 â”‚
â”‚   â†“                                             â”‚
â”‚   MLflow finalizes: Experiment complete         â”‚
â”‚                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RESULT:                                                    â”‚
â”‚  âœ“ Model trained and saved locally                         â”‚
â”‚  âœ“ Model tracked in MLflow (params + metrics + model)      â”‚
â”‚  âœ“ Model registered in MLflow Model Registry               â”‚
â”‚  âœ“ Model registered in local registry                      â”‚
â”‚  âœ“ All logs saved                                          â”‚
â”‚  âœ“ Can view in MLflow UI: http://127.0.0.1:5002           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Simple Comparison: Before vs After

### **BEFORE MLflow:**

```python
# Train model
trainer = ModelTrainer(config)
trainer.train(X_train, y_train)

# Evaluate
evaluator = ModelEvaluator(config)
metrics = evaluator.evaluate(y_val, predictions)

# Save
trainer.save_model()  # Saved to disk

# Problem:
# - Hard to compare experiments
# - Metrics scattered in different files
# - No visual dashboard
```

### **AFTER MLflow:**

```python
# Start tracking
mlflow_tracker = MLflowTracker(config)  # â† NEW
mlflow_tracker.start_run("experiment_1")  # â† NEW

# Log parameters
mlflow_tracker.log_params({'n_estimators': 150})  # â† NEW

# Train model (same as before)
trainer = ModelTrainer(config)
trainer.train(X_train, y_train)

# Evaluate (same as before)
evaluator = ModelEvaluator(config)
metrics = evaluator.evaluate(y_val, predictions)

# Log metrics
mlflow_tracker.log_metrics(metrics)  # â† NEW

# Log model
mlflow_tracker.log_model(trainer.model, "my_model")  # â† NEW

# End tracking
mlflow_tracker.end_run()  # â† NEW

# Save locally too
trainer.save_model()

# Benefits:
# âœ“ All experiments in one place (MLflow UI)
# âœ“ Easy comparison (visual charts)
# âœ“ Model versioning (v1, v2, v3)
# âœ“ One-click serving
```

---

## ğŸ’¡ Real-World Example

**Scenario:** You want to find the best number of trees

**Without MLflow (hard way):**
```bash
# Try 100 trees
# Edit config manually
python main_pipeline.py
# Write down: "100 trees â†’ RMSE: 48,726"

# Try 150 trees
# Edit config manually
python main_pipeline.py
# Write down: "150 trees â†’ RMSE: 48,677"

# Try 200 trees
# Edit config manually
python main_pipeline.py
# Write down: "200 trees â†’ RMSE: 48,500"

# Compare manually (look at your notes)
# Best: 200 trees!
```

**With MLflow (easy way):**
```bash
# Try 100 trees
# Edit config: n_estimators: 100
dvc repro
# MLflow automatically records everything

# Try 150 trees
# Edit config: n_estimators: 150
dvc repro
# MLflow automatically records everything

# Try 200 trees
# Edit config: n_estimators: 200
dvc repro
# MLflow automatically records everything

# Compare in UI:
# Open: http://127.0.0.1:5002
# Click: Experiments â†’ Select all 3 â†’ Compare
# See: Beautiful chart showing 200 is best!
```

---

## ğŸ” What Gets Saved Where

### **Local Files (Always saved):**
```
models/saved_models/
  â”œâ”€ model_random_forest_*.joblib  â† Trained model
  â”œâ”€ scaler.joblib
  â””â”€ encoder.joblib

models/model_registry/
  â””â”€ registry.json  â† Local registry

logs/
  â””â”€ evaluation_report.json  â† Metrics
```

### **MLflow Files (NEW):**
```
logs/mlruns/
  â”œâ”€ 0/                           â† Default experiment
  â”œâ”€ 223965389543970541/          â† housing_price_prediction experiment
  â”‚   â”œâ”€ abc123/                  â† Run 1 (150 trees)
  â”‚   â”‚   â”œâ”€ params/
  â”‚   â”‚   â”‚   â”œâ”€ n_estimators    (contains: "150")
  â”‚   â”‚   â”‚   â””â”€ max_depth       (contains: "20")
  â”‚   â”‚   â”œâ”€ metrics/
  â”‚   â”‚   â”‚   â”œâ”€ rmse            (contains: "48677")
  â”‚   â”‚   â”‚   â””â”€ r2_score        (contains: "0.8192")
  â”‚   â”‚   â”œâ”€ artifacts/
  â”‚   â”‚   â”‚   â””â”€ model/          â† Trained model
  â”‚   â”‚   â””â”€ meta.yaml           â† Metadata
  â”‚   â”‚
  â”‚   â””â”€ def456/                  â† Run 2 (100 trees)
  â”‚       â”œâ”€ params/
  â”‚       â”œâ”€ metrics/
  â”‚       â””â”€ artifacts/
  â”‚
  â””â”€ models/                      â† Model Registry
      â””â”€ housing_price_predictor/
          â”œâ”€ version-1/
          â”œâ”€ version-2/
          â””â”€ version-3/
```

---

## ğŸ¯ Key Takeaways

### **What MLflow Added:**

1. **Automatic Experiment Tracking**
   - Every run recorded automatically
   - Parameters and metrics saved
   - Models versioned

2. **Visual Dashboard (MLflow UI)**
   - http://127.0.0.1:5002
   - Compare experiments visually
   - Charts and graphs

3. **Model Registry**
   - Version control for models (v1, v2, v3)
   - Lifecycle management (dev â†’ staging â†’ production)
   - Easy rollback

4. **Model Serving**
   - One-command deployment
   - REST API automatically created
   - Production-ready

### **Classes Involved:**

| Class | File | Purpose | New/Modified |
|-------|------|---------|--------------|
| **MLflowTracker** | `src/mlflow_tracker.py` | MLflow wrapper | âœ… NEW |
| **ModelTrainer** | `src/models/train.py` | Train models | Existing |
| **ModelEvaluator** | `src/evaluation/evaluate.py` | Evaluate models | Existing |
| **ModelRegistry** | `src/models/registry.py` | Local versioning | Existing |
| **PipelineLogger** | `src/pipeline_logger.py` | Logging | Existing |
| **FeatureEngineer** | `src/features/engineer.py` | Feature engineering | Existing |
| **DataIngestor** | `src/data/ingest.py` | Data loading | Existing |

**Summary:**
- Added **1 new class** (MLflowTracker)
- Modified **0 existing classes** (just use them!)
- Created **1 new pipeline script** that uses all classes together

---

## âœ… Summary

**What we did:**
1. Created `MLflowTracker` class (makes MLflow easy)
2. Created new training script that uses MLflowTracker
3. Updated config to enable MLflow
4. Updated DVC to use new training script

**Result:**
- All experiments tracked automatically
- Visual dashboard to compare models
- Model registry with versioning
- One-command model serving

**You can now:**
- âœ… Train models with automatic tracking
- âœ… Compare experiments in UI
- âœ… Register models with versions
- âœ… Serve models as REST API

---

**Simple enough?** Try running another experiment and see it appear in the UI! ğŸš€
